"use strict";(self.webpackChunkwiki=self.webpackChunkwiki||[]).push([[7151],{6156:(e,i,t)=>{t.r(i),t.d(i,{assets:()=>d,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>r,toc:()=>l});var s=t(4848),n=t(8453);const o={title:"Developer Resources",sidebar_position:6},a=void 0,r={id:"developer-resources/index",title:"Developer Resources",description:"What is View Assist?",source:"@site/docs/developer-resources/index.md",sourceDirName:"developer-resources",slug:"/developer-resources/",permalink:"/View-Assist/docs/developer-resources/",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:6,frontMatter:{title:"Developer Resources",sidebar_position:6},sidebar:"tutorialSidebar",previous:{title:"M5Stack Atom Echo",permalink:"/View-Assist/docs/supported-devices/esphome-devices/m5stack-atom-echo"},next:{title:"Frequently Asked Questions",permalink:"/View-Assist/docs/faq"}},d={},l=[{value:"What is View Assist?",id:"what-is-view-assist",level:2},{value:"What does a VA display look like",id:"what-does-a-va-display-look-like",level:2},{value:"What are VA modes?",id:"what-are-va-modes",level:2},{value:"How does VA determine which VA device is requesting?",id:"how-does-va-determine-which-va-device-is-requesting",level:2}];function c(e){const i={code:"code",h2:"h2",li:"li",p:"p",pre:"pre",ul:"ul",...(0,n.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(i.h2,{id:"what-is-view-assist",children:"What is View Assist?"}),"\n",(0,s.jsx)(i.p,{children:"View Assist (VA) is a framework for Home Assistant (HA) Assist satellites.  Some of the core features:"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"VA brings satellites with displays (view_audio) and without (audio_only) together in a group that allows for interaction between satellites."}),"\n",(0,s.jsx)(i.li,{children:"VA provides preconfigured views and custom sentence automations to extend the HA Assist capabilities"}),"\n",(0,s.jsx)(i.li,{children:"VA provides device control automations which support a variety of display related functionality"}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"what-does-a-va-display-look-like",children:"What does a VA display look like"}),"\n",(0,s.jsx)(i.p,{children:"A normal VA custom sentence is handled like this:"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:'User makes a request using the trigger for a custom sentence like "How\'s the weather"'}),"\n",(0,s.jsx)(i.li,{children:"The custom sentence blueprint identifies the keyword and triggers the automation"}),"\n",(0,s.jsx)(i.li,{children:"VA attempts to determine which device is being used (described later) and sets variables for the VA device and that devices attributes like mediaplayer_device, musicplayer_device, and display_device"}),"\n",(0,s.jsx)(i.li,{children:"The automation will then do specialized tasks associated with the custom sentence.  Some examples would be setting the title text in the top left corner or setting device entities to show (like camera.doorbell).  This is done using the set_state.py action call"}),"\n",(0,s.jsx)(i.li,{children:"VA may change the displayed view by making an action call to the BrowserMod (BM) action navigate."}),"\n",(0,s.jsx)(i.li,{children:"VA control automation watches for view changes.  When this happens, the VA device starts the associated timer"}),"\n",(0,s.jsx)(i.li,{children:"VA will often give audio feedback"}),"\n",(0,s.jsx)(i.li,{children:"When the timer expires VA will call the BM navigate action call to send the display back to a view.  This view is based on the mode setting.  Currently, if mode is set to normal, the displayed view will be the default view which is commonly set to the clock view.  If mode is set to music then the displayed view will be the configured view for music"}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"what-are-va-modes",children:"What are VA modes?"}),"\n",(0,s.jsx)(i.p,{children:"VA modes control how VA acts and looks.  These modes can be extended.  Currently these are the modes available:"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Normal - This mode is the default.  No icon is shown to indicate it is active.  Behavior is described above"}),"\n",(0,s.jsx)(i.li,{children:"Music - Music mode is set by automations using music playback.  No icon is shown to indicate it is active.  Behavior is described above"}),"\n",(0,s.jsx)(i.li,{children:"Hold - Hold mode is set by taping an open area on any view or by automation.  A hand icon is shown when it is active.  Hold mode prevents the timer expiring from changing the view.  This is useful when wanting to interact with a view for longer than the timeout.  An example would be calling for a security camera to be displayed and to leave it on the screen indefinitely.  Leaving hold mode can be done by taping the hand icon, use a voice command from the device functions blueprint to change modes, or by automation"}),"\n",(0,s.jsx)(i.li,{children:"Cycle - Cycle view is set by voice using device functions blueprint to change modes or by automation.  Icon shown is arrows in a circle.  Cycle mode will cycle through a list of views set in the device attributes cycle.  The automation will use the VA device's timer to control the time that each view is displayed.  The views will continue to loop until cycle mode is exited by clicking the icon to return to normal mode or by automation"}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"how-does-va-determine-which-va-device-is-requesting",children:"How does VA determine which VA device is requesting?"}),"\n",(0,s.jsx)(i.p,{children:"VA must determine which device is being used for a request.  This is done the same in each custom sentence blueprint.  This block of code is used in each blueprint:"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{children:"      target_satellite_device: |-\n        {% for sat in expand(group_entity) %}\n          {% if device_id(sat.attributes.mic_device)  == trigger.device_id %}\n            {{ sat.entity_id }}\n          {% endif %}\n        {% endfor %}\n      target_display_device: \"{{ device_id(state_attr(target_satellite_device, 'display_device')) }}\"\n      target_mediaplayer_device: \"{{ state_attr(target_satellite_device, 'mediaplayer_device') }}\"\n      target_satellite_device_type: \"{{ state_attr(target_satellite_device, 'type') }}\"\n"})}),"\n",(0,s.jsx)(i.p,{children:"target_satellite_device is set by looking through all members of the satellite group (normally group.view_assist) and looking for a match of the automation's trigger.device_id and the microphone attribute of each VA device in the group.  Once the target_satellite_device is set, other attributes like target_mediaplayer_device and target_satellite_device can be derived and set."})]})}function h(e={}){const{wrapper:i}={...(0,n.R)(),...e.components};return i?(0,s.jsx)(i,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},8453:(e,i,t)=>{t.d(i,{R:()=>a,x:()=>r});var s=t(6540);const n={},o=s.createContext(n);function a(e){const i=s.useContext(o);return s.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function r(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:a(e.components),s.createElement(o.Provider,{value:i},e.children)}}}]);